
Activities for the week
1. Input the master data into GE.db. Data has already been loaded:
- Databases
- Data sets
- Group - Keyge
- Category â€“ Keyge
- Keyge (chemicals, genes, diseases, paths, and anatomy) CTD data originates from the NIH. I removed the CTD prefixes and added them to us.
* The files already processed are in the loader folder.
Pending:
-          Raise other keyge and prefixes
-          Prepare loads for Links between keyge and word
2 . I have already simulated to load data for the entire production environment of the data from the sources.
3. Improve the documentation process with all commands already created at the moment.
  


Processes under development:
Continue the development of the process filter
Explain a web interface for other functionality.
Optional: Create a Keyge Links extractor to query in Tableau or other Data Visualization tools


Novas funcoes implementadas Jul 6
 - Adicionado campo para opcao de manter os arquivos baixados
 - Rotina em Prepare para eliminar ou manter arquivos baixados
 - Tratamento quando temos compactacao e os arquivos estao com os mesmos nomes do cadastro do dataset


Agosto 1 / 2022
- Implementar campo de pesquisa no ADMIN
- Preparar dados mestres

Agosto 5 / 2022
- criar script para converter xml para csv (ler arquivos do HMDB)




Proximos passos:
--> Verificar se temos mais palavras para carregar
--> simular uma carrega
--> Tutorial do sistema
--> desenvolver interface via commande line para filtro.
--> desenvolver interface WEB para consultas. 



Agosto 15

-- Como sem o Commute iremos tratar palavras compostas???


Retirada do processo Commute: 



Commute tem a funcao de substituir 

Aug18
Testes com o Reduce e MAP individualmente

Aug 19
- ajuste nos novos processos com o desmembramento do MAPREDUCE



Inicio do processo todo
# HTTP_NOT_MODIFIED  -  azul 
sem espaco

        Avisos antes de processar que impedem o processamento ou aborta o processamento
        # HTTP_BAD_REQUEST - vermelho fraco
        Add dois espacos

        Inicio do processaemnto de um dataset
        # HTTP_NOT_MODIFIED  -  azul 
        Add dois espaco

                Mensagems normais do processamento do Dataser
                HTTP_SUCESS  - branco
                add 4 espacos

                Mensagens de ERRO no processamento do dataset
                HTTP_BAD_REQUEST - vermelho fraco
                add 4 espacos

                Mensages de Warning 
                # HTTP_NOT_FOUND - amarelo claro
                Add 4 espacos

                termino do processamento do dataset
                # HTTP_REDIRECT - verde claro
                add 4 espacos

            Mensages de Warning 
            # HTTP_NOT_FOUND - amarelo claro
            Add 2 espacos

            Mensagems se o Dataset esta OK e nao procecissa de processamento
            HTTP_INFO  - branco
            add 4 espacos

Termino do processamento do processo
# SUCESS
Sem espacos




    #  HTTP_INFO  - branco ngrito
    # HTTP_SUCESS - branco
    # HTTP_NOT_MODIFIED  -  azul
    # HTTP_NOT_FOUND - amarelo claro
    # HTTP_BAD_REQUEST - vermelho fraco
    # HTTP_REDIRECT - verde claro
    # HTTP_SERVER_ERROR - roxo
    # ERROR    - erro nivel 2



22 Agosto
- teste com 9gb de dataset
- Sincronizar com icds
- ajustar dados mestres
    Ajustar dataset: nao podemos deixar todos em lower case
- processar duas datasets
    - via termianl
    - via job

- testar ECHO
- Relatorio ler os outros e fazer o MAPREDUCE
- criar rotina para consultar o workflow

Estudar sobre IRB
Acomparnhar a GOLL4

23 Agosto